{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACE DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>10.1 Facebook</u>  \n",
    "Imagine social graphs for Fb and Twitter. How do they differ? \n",
    "What metrics should use for measuring differ\n",
    "\n",
    "**CQ**  \n",
    "- what is social graph here. Could we consider it like pairs (user1, user2) - and what is user-match definition?\n",
    "example some actions like following, adding in friends (other: comments etc, but ts harder)\n",
    "- do we have this (user1, user2), ... tables fro both products and also user matching in products?\n",
    "- in what user segment we make comparing? should we consider users who use just one product? (ex: no)\n",
    "- for what purpose we could use this differ? do we need some actions on this measurements?\n",
    "\n",
    "**Solution**  \n",
    "Assume we work with segment of users who both use this products & have matching\n",
    "- we could get numbers like: overlap matching pairs, not overlap - could use some ratio  \n",
    "- for sure Fb have bigger graph that Tw, so have much more users\n",
    "- overlap ratio depend of user segment: working collegues, bloggers etc\n",
    "- we can compare aggs like: avg matchs per user in each product if we dont have common base\\\n",
    "\n",
    "**From book**  \n",
    "1) доп. шаг - уточнить как работают обе платформы и на что сфокусированы. Fb больше про общение и дружбу,  \n",
    "Tw это follower-ориентированная платформа. (!) В Tw чаще возможны сценарии односторонней связи,  \n",
    "когда читатель подписан на инфлюэнсера без обратной подписки  \n",
    "Кроме того в Твиттере сравнительно небольшое кол-во юзеров с большой подписочной базой  \n",
    "\n",
    "2) метрика средней степени узла (ср кол-во связей клиента) подходящая общая метрика сравнения  \n",
    "При этом можно сфокусироваться на сегментах - клиенты с оч большим кол-вом узлов и относительно малым и  \n",
    "сравнивать их распределения (доли клиентов имеющих x% узлов, перцентильные кривые)\n",
    "  \n",
    "Можно использовать метрику skewness для характеристики степени скошенности распределения кол-ва  \n",
    "связей в рамках одной ноды\n",
    "\n",
    "---\n",
    "<u>10.2 Uber</u>  \n",
    "Why does surge pricing exists? Metrics checking effective working of surge pricing?  \n",
    "\n",
    "**CQ**  \n",
    "- CQ about business model. Do we talk about uber-delivery and taxi? So we have two-side market with  \n",
    "drivers and driver consumers (riders or people waiting delivery).  \n",
    "So, we are talking about surge pricing depending on time and geo online? other args?  \n",
    "We area talking about pricing to consumers - example, riders in taxi.  \n",
    "\n",
    "**Solution**  \n",
    "Lets talk about taxi. We have some geo/time demand and suppply ratio. It could be situation (example rain)  \n",
    "when many there are many riders and not enough taxi drivers. In this case we consider increase  \n",
    "waiting time and lowering service quality. Want to fix imbalance because - lowering quality =  \n",
    "problems with clients, high load to support etc.  \n",
    "  \n",
    "Metrics. Surge pricing working well when there is no great imbalance.  \n",
    "If pricing is too high = few riders; otherwise = too much riders, few drivers.  \n",
    "Proxy = count of orders per count of drivers in moment. Should be as normal. Long metric is  \n",
    "avg waiting time per one client.  \n",
    "\n",
    "**From book**   \n",
    "NPS, LTV, creation and cancellation of orders  \n",
    "Also monitoring metrics: surge time, price multiplicator, number of users in affected area\n",
    "\n",
    "---\n",
    "<u>10.3 Airbnb</u>  \n",
    "What factors make a/b testing is difficult in abnb platform\n",
    "  \n",
    "**CQ**  \n",
    "- airbnb = two-side business - hosts & tenants. What kind of a/b testing should check (maybe both)  \n",
    "- what type of ab test we should focus on: design, pricing, matching algorithms?  \n",
    "- what segments: all or some countries?  \n",
    "- what platform we affect? mobile or desktop\n",
    "\n",
    "**Solution**  \n",
    "- long term problem: ltv horizont per one host is long  \n",
    "if we affect matching algoritms and more users get bad hosts - we can get rising of bad reviews with delay  \n",
    "if work with mobile - problem of relize delays (user should update his app)  \n",
    "- network effect: if we change pricing to some hosts - it can affect control tenants (should check geo/time)  \n",
    "\n",
    "**From book**  \n",
    "- complexity of user flow: there are many steps that outside of airbnb control (communication hosts and tenants)  \n",
    "- booking process is difficult and sometimes hard-predictable long (user can book appartment in two months in future, so it hard to detect some metric results here)  \n",
    "- hard user in experiment allocation cause sometimes airbnb booking involve many tenants as well;  \n",
    "also one user can user many devices to make reservation, we need to preprocess data to handle this problem  \n",
    "\n",
    "---\n",
    "<u>10.4 Google</u>  \n",
    "We pay to Mozilla X dollars for Google to be default search engine. Mozilla asking 2X now. Should we take a deal?  \n",
    "How would you estimate upper bound for payments?  \n",
    "  \n",
    "**CQ**  \n",
    "We need to pay less than Y, where Y = financial effect of this deal.  \n",
    "- how could we track users: could we understand that user make actions with this browser;  \n",
    "colud we attribute user between browsers and platforms (example mobile)\n",
    "- do we know main mozilla search engine alternatives? which engine will be default if not google?\n",
    "\n",
    "\n",
    "**Solution**  \n",
    "Financial effect components:\n",
    "- ad revenue directly from mozilla users (who search in mozilla with google and make clicks)    \n",
    "- effect of other google services which use mozilla-users:  \n",
    "mozilla-user create google account -> ltv including next transfer to google chrome  \n",
    "but some users could create account without default searcher - maybe use benchmarks from other browsers  \n",
    "mozilla-user dont create account but use google sevices (check with cookies) = ltv  \n",
    "If we know google-ltv for not google_search-default initial users - could compare revenue decrease.   \n",
    "Thats good assumption - scale how much ltv we could extract from other non default browsers.  \n",
    "  \n",
    "Then we could compare this financial effect with alternative investition channels - if its better  \n",
    "to use Y in this channel or other.\n",
    "\n",
    "**From Book**  \n",
    "Main CQ = completely understand WHY google need their search as default in mozilla   \n",
    "Reputation and PR risks - users can suspect that Google have privacy problems if Mozilla prefer to switch  \n",
    "If users from Mozilla will not go to google services like Google Map etc - it could make worse relevance  \n",
    "of quality of this services - users could go to competitors services.  \n",
    "Also google search engine depends on user traffic - so it should be estimated problems with engine if  \n",
    "google will be not default search engine in Mozilla\n",
    "  \n",
    "---\n",
    "<u>10.5 Linkedin</u>  \n",
    "Linkedin Feed. What metric would you use to track engagement? How would you improve this metrics?  \n",
    "  \n",
    "**CQ**  \n",
    "- How Feed works now, what info included\n",
    "Lets consider: follow posts, recommended posts & events, ad\n",
    "- For what segment we could check engagement: influencers, ordinal followers, companies?  \n",
    "- what actions can now users do in feed? Make posts, go to events, follow users\n",
    "- whats typical behaviour of target user segment - how much users make target actions? \n",
    "  \n",
    "**Solution**  \n",
    "Engagement define how much user invole in using functionality of this feature. More engagement users has  \n",
    "greater retention and better monetisation potential. Engagement metric should be short term like  \n",
    "good proxy to retention.  \n",
    "We have cluster of users who start use linkedin intensive when need to find job. Better retention =  \n",
    "better chance to use monetisation product etc.  \n",
    "  \n",
    "First level of engagement is spending more time to research useful information.  \n",
    "Second level is conversion to some target action - example follow, make comment, post etc.  \n",
    "We could check on historical period which correlation is better with  \n",
    "Also could check correlation with this engagement actions to chance to answer on apply (conversation)  \n",
    "  \n",
    "To increase engagement level (ex. lets make conversion to comment/likes/followings) we could:  \n",
    "- make tests with better recommendations \n",
    "- tests with design to suggest on Feed more relevant companies etc\n",
    "\n",
    "**Book info**  \n",
    "High-level metrics of engagement ofcourse is MAU, DAU etc - how often active users in service.  \n",
    "You can create scored metrics like:  \n",
    "- content consumption score (likes, views, event checks etc)  \n",
    "- content creation score (posts cnt, comments, sharings etc)\n",
    "\n",
    "To watch how to improve except experiments you could:\n",
    "- check important features that affect engagement metrics and try to improve it (check with rand.forests example) \n",
    "- check competitors, what kind of features do they have released\n",
    "\n",
    "---\n",
    "<u>10.6 Lyft</u>  \n",
    "You try to understand if new UI rider app increase riders taken cnt. How to split groups in about tests and  \n",
    "be ensured that you have balanced groups?\n",
    "\n",
    "**Solution**  \n",
    "Main problem is network effect. If we increase test-riders conversion - we increase orders in drivers and  \n",
    "it could affect control-riders activity too. We could use metric like riders cnt per user who open app.  \n",
    "We couldn't use switchback time here cause user will see changing UI and it should affect him bad.  \n",
    "We could use geo splitting for better to separate groups - we could choose group config in control and test  \n",
    "checking that in A/A tests validation all will be good (control I type error).  \n",
    "\n",
    "---\n",
    "<u>10.7 Amazon</u>  \n",
    "If you plot avg revenue per seller on Amazon - what would the shape of distribution?  \n",
    "  \n",
    "**CQ**  \n",
    "Lets define revenue here. Revenue = income - amazon tax?  \n",
    "Should we check all countries, so we could use US dollar as main currency?  \n",
    "Also we consider all segments of amazon sellers like = big companies & also smb.  \n",
    "Also abut avg - what period we use - avg for lifetime? For new users we will have small revenue  \n",
    "respect time of their service living.\n",
    "\n",
    "**Solution**  \n",
    "In any marketplaces we have very big companies that have huge revenue tail - so thats outliers.  \n",
    "So, i guess we have long right tail distribution.  \n",
    "If we have clearly separate seller segments - we could have several max of this distribution.  \n",
    "Near local max it could be normal distribution cause very much sellers - so CLT.  \n",
    "New users = close to zero maximum for that segment.  \n",
    "\n",
    "**From book**  \n",
    "In many business main distribution is Pareto, where 80% of revenue generates about 20% of users.  \n",
    "So we have super right skewed distribution with small cnt of big-revenue users and large cnt of small rev users.  \n",
    "  \n",
    "---\n",
    "<u>10.8 Facebook</u>  \n",
    "Whats posts Facebook should remove beside those who needed to be removed according by law? What features could you use to identify this posts  \n",
    "\n",
    "**Solution**  \n",
    "We should remove posts which make negative reputational and engagement effect to FB users.  \n",
    "We consider that legally we should remove: scam, posts with violence etc.  \n",
    "  \n",
    "Also we could use some desinformation posts (example, again COVID) - which could hurt people with  \n",
    "using this wrong information. It could be political, pseudo-medicine, etc posts.  \n",
    "  \n",
    "Trade-off: we will loose audithory which are dedicated with this wrong ideas; also have reputational risks  \n",
    "like strict censorship platform.  \n",
    "  \n",
    "For reveal posts with desinformation we could use ML models, which will be trained from examples created by  assesors. It could be classifier with several rarget types of posts - example LLM or boosting.  \n",
    "  \n",
    "**From book**  \n",
    "False positive and false negative cases when you use your model to classify posts  \n",
    "FP = posts really not bad, but model hide it - so people colud post less or deactivate accounts etc.  \n",
    "FN = bad posts not deactivated so it affect users with negative.  \n",
    "  \n",
    "---\n",
    "<u>10.9 Amazon</u>  \n",
    "Amazon books: books with more complete author profiles sells more.  \n",
    "Team make autofill profiles with Wikipedia info, but sales doesnt changes - why?  \n",
    "\n",
    "**Solution**  \n",
    "1) Correlation not causation. Example, more famous authors have better selling books and  \n",
    "they also better fill  their profile - but real factor which affect book salling is \"famous\"  \n",
    "\n",
    "2) Do you auto-fill actually:\n",
    "- part of information that have correlation. Maybe text dont have but author photo have and you match just text  \n",
    "- enough percent of profiles (if there are many unmatched profiles - it could give not enough shift)\n",
    "- accuracy of mathing (is it usually exact right author information - should validate it)  \n",
    "  \n",
    "---\n",
    "<u>10.10 Snapchat</u>  \n",
    "We see overall 5% decrease in DAU - trend that had been consistent over the week. How to determine a reason?  \n",
    "\n",
    "**CQ**  \n",
    "Is it 5% decrease comparing prev week or YoY? Lets tell about WoW effect. \n",
    "What is active users in Snapchat? User who open app during the day.  \n",
    "\n",
    "\n",
    "**Solution**  \n",
    "First of all - is it significant decrease? (lets say, yes)  \n",
    "  \n",
    "We can check three type of reasons:  \n",
    "internal:\n",
    "- logging problem, check if all okey\n",
    "- any releases before week start (check increase in segments: platform, devices, user_type etc)  \n",
    "- marketing activity (start/end ad campaigns)\n",
    "- any bugs in pipeline (check funnel; example, problem with push notifications etc)\n",
    "  \n",
    "external:\n",
    "- is any competitors activity (TikTok, Telegram etc) in your market?\n",
    "- is any holidays, world events that could affect, politics regulations\n",
    "- seassonable (check trend with previous years)\n",
    "\n",
    "---\n",
    "<u>10.11 Pinterest</u>  \n",
    "You ship new ranking algo. What metrics you'll use to measure impact.  \n",
    "  \n",
    "**CQ**  \n",
    "Check some algo details. Is it feed ranking algo? Is any segments (users, geo, ...) where algo works?  \n",
    "Lets assume - all site, main feed, algo after you put query.  \n",
    "What main purpouse of algo, what metric we optimise? Lets: adding in favorite.  \n",
    "\n",
    "**Solution**  \n",
    "We have AARRR framework = acquisition, activation, retention, referral, revenue  \n",
    "If algo touch unlogged users - activation metrics = percent of users with sign in.  \n",
    "Engagement metrics: conv and avg cnt of adding ideas in favorites per session/users.    \n",
    "Monetisation metrics: if we use ad = time per session; ad CTR; CTR to partners.  \n",
    "According purpose: lets consider adding favorites (more engagement), but guardrail: ad, activation.  \n",
    "Also, if we have different segments: could check individually.  \n",
    "  \n",
    "**From book**  \n",
    "Check if algo have UI changing moments  \n",
    "Also check main company mission goals and connection of algo potential impact and goals.  \n",
    "(!) user search cnt and user time spend is problem metrics: bad algo could tend to make search experience worse.  \n",
    "But user spend time could be guardrail metric if it depends on ad.  \n",
    "\n",
    "---\n",
    "<u>10.12 Netflix</u>  \n",
    "sci-fi TV shows have less total watch time than other similar categories.  \n",
    "What metrics should use to determine: if people are not interested in that category  \n",
    "OR category okey but content bad. Another words: demand or supply problems.  \n",
    "  \n",
    "**CQ**  \n",
    "Lets determine category which we discuss = TV shows.  \n",
    "So, we assume that current watch time is a problem comparing example \"late night shows\", \"cooking shows\" etc.  \n",
    "Total watch time = total time during **equivalent** period for all comparing categories (so, its not new)  \n",
    "Also, are we have enough content of sci-fi on platform? So, its not a problem of lack of supply.  \n",
    "  \n",
    "**Solution**  \n",
    "So, we assume that we have equivalent potential watch time supply comparing other categories.  \n",
    "watch time (per period) = watch_users_cnt * watch_time_per_user  \n",
    "  \n",
    "If users are not interesting with sci-fi we could check it in small watch user cnts  \n",
    "\n",
    "We should check funnel: is it simple to find this part in platform + recommendation issues.  \n",
    "Is new users have equal way to check this category comparing similar categories?  \n",
    "\n",
    "If conversion from view category to start watching is low - maybe we have demand problem.  \n",
    "Also, we could have bad images, posters with low conversion = thats mean content problem  \n",
    "We could check search cnts - where users try to find shows from this category.  \n",
    "  \n",
    "Content quality problem will be if we have problem with metrics like:  \n",
    "watch_time_per_user, retenetion to watch in this category, proxy-metrics like like/dislike, comments.  \n",
    "\n",
    "**From book**  \n",
    "Could check also segments: maybe in some countries we don't have normal translation or other - content problem.  \n",
    "We could use external benchmarks - what are engagement metrics (conversion from start to finish series)  \n",
    "in this  category in market and what is our results comparing it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
