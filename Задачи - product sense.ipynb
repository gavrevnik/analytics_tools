{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Always check main goal - what for we need to solve task, how we would use results\n",
    "If you suggest any metrics - you should validate it if this metrics have problems to be break or have some problem with goal correlation or causation. So check all you brainstorm-metrics.\n",
    "2. If you need to suggest any algo - check size of problem. Example, how many items should we  \n",
    "predict = dataset size, frequency of preiction, other technical aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Ace Data Science interview - product sense exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<u>10.1 Facebook</u>  \n",
    "Imagine social graphs for Fb and Twitter. How do they differ? \n",
    "What metrics should use for measuring differ\n",
    "\n",
    "**CQ**  \n",
    "- what is social graph here. Could we consider it like pairs (user1, user2) - and what is user-match definition?\n",
    "example some actions like following, adding in friends (other: comments etc, but ts harder)\n",
    "- do we have this (user1, user2), ... tables fro both products and also user matching in products?\n",
    "- in what user segment we make comparing? should we consider users who use just one product? (ex: no)\n",
    "- for what purpose we could use this differ? do we need some actions on this measurements?\n",
    "\n",
    "**Solution**  \n",
    "Assume we work with segment of users who both use this products & have matching\n",
    "- we could get numbers like: overlap matching pairs, not overlap - could use some ratio  \n",
    "- for sure Fb have bigger graph that Tw, so have much more users\n",
    "- overlap ratio depend of user segment: working collegues, bloggers etc\n",
    "- we can compare aggs like: avg matchs per user in each product if we dont have common base\\\n",
    "\n",
    "**From book**  \n",
    "1) доп. шаг - уточнить как работают обе платформы и на что сфокусированы. Fb больше про общение и дружбу,  \n",
    "Tw это follower-ориентированная платформа. (!) В Tw чаще возможны сценарии односторонней связи,  \n",
    "когда читатель подписан на инфлюэнсера без обратной подписки  \n",
    "Кроме того в Твиттере сравнительно небольшое кол-во юзеров с большой подписочной базой  \n",
    "\n",
    "2) метрика средней степени узла (ср кол-во связей клиента) подходящая общая метрика сравнения  \n",
    "При этом можно сфокусироваться на сегментах - клиенты с оч большим кол-вом узлов и относительно малым и  \n",
    "сравнивать их распределения (доли клиентов имеющих x% узлов, перцентильные кривые)\n",
    "  \n",
    "Можно использовать метрику skewness для характеристики степени скошенности распределения кол-ва  \n",
    "связей в рамках одной ноды\n",
    "\n",
    "---\n",
    "<u>10.2 Uber</u>  \n",
    "Why does surge pricing exists? Metrics checking effective working of surge pricing?  \n",
    "\n",
    "**CQ**  \n",
    "- CQ about business model. Do we talk about uber-delivery and taxi? So we have two-side market with  \n",
    "drivers and driver consumers (riders or people waiting delivery).  \n",
    "So, we are talking about surge pricing depending on time and geo online? other args?  \n",
    "We area talking about pricing to consumers - example, riders in taxi.  \n",
    "\n",
    "**Solution**  \n",
    "Lets talk about taxi. We have some geo/time demand and suppply ratio. It could be situation (example rain)  \n",
    "when many there are many riders and not enough taxi drivers. In this case we consider increase  \n",
    "waiting time and lowering service quality. Want to fix imbalance because - lowering quality =  \n",
    "problems with clients, high load to support etc.  \n",
    "  \n",
    "Metrics. Surge pricing working well when there is no great imbalance.  \n",
    "If pricing is too high = few riders; otherwise = too much riders, few drivers.  \n",
    "Proxy = count of orders per count of drivers in moment. Should be as normal. Long metric is  \n",
    "avg waiting time per one client.  \n",
    "\n",
    "**From book**   \n",
    "NPS, LTV, creation and cancellation of orders  \n",
    "Also monitoring metrics: surge time, price multiplicator, number of users in affected area\n",
    "\n",
    "---\n",
    "<u>10.3 Airbnb</u>  \n",
    "What factors make a/b testing is difficult in abnb platform\n",
    "  \n",
    "**CQ**  \n",
    "- airbnb = two-side business - hosts & tenants. What kind of a/b testing should check (maybe both)  \n",
    "- what type of ab test we should focus on: design, pricing, matching algorithms?  \n",
    "- what segments: all or some countries?  \n",
    "- what platform we affect? mobile or desktop\n",
    "\n",
    "**Solution**  \n",
    "- long term problem: ltv horizont per one host is long  \n",
    "if we affect matching algoritms and more users get bad hosts - we can get rising of bad reviews with delay  \n",
    "if work with mobile - problem of relize delays (user should update his app)  \n",
    "- network effect: if we change pricing to some hosts - it can affect control tenants (should check geo/time)  \n",
    "\n",
    "**From book**  \n",
    "- complexity of user flow: there are many steps that outside of airbnb control (communication hosts and tenants)  \n",
    "- booking process is difficult and sometimes hard-predictable long (user can book appartment in two months in future, so it hard to detect some metric results here)  \n",
    "- hard user in experiment allocation cause sometimes airbnb booking involve many tenants as well;  \n",
    "also one user can user many devices to make reservation, we need to preprocess data to handle this problem  \n",
    "\n",
    "---\n",
    "<u>10.4 Google</u>  \n",
    "We pay to Mozilla X dollars for Google to be default search engine. Mozilla asking 2X now. Should we take a deal?  \n",
    "How would you estimate upper bound for payments?  \n",
    "  \n",
    "**CQ**  \n",
    "We need to pay less than Y, where Y = financial effect of this deal.  \n",
    "- how could we track users: could we understand that user make actions with this browser;  \n",
    "colud we attribute user between browsers and platforms (example mobile)\n",
    "- do we know main mozilla search engine alternatives? which engine will be default if not google?\n",
    "\n",
    "\n",
    "**Solution**  \n",
    "Financial effect components:\n",
    "- ad revenue directly from mozilla users (who search in mozilla with google and make clicks)    \n",
    "- effect of other google services which use mozilla-users:  \n",
    "mozilla-user create google account -> ltv including next transfer to google chrome  \n",
    "but some users could create account without default searcher - maybe use benchmarks from other browsers  \n",
    "mozilla-user dont create account but use google sevices (check with cookies) = ltv  \n",
    "If we know google-ltv for not google_search-default initial users - could compare revenue decrease.   \n",
    "Thats good assumption - scale how much ltv we could extract from other non default browsers.  \n",
    "  \n",
    "Then we could compare this financial effect with alternative investition channels - if its better  \n",
    "to use Y in this channel or other.\n",
    "\n",
    "**From Book**  \n",
    "Main CQ = completely understand WHY google need their search as default in mozilla   \n",
    "Reputation and PR risks - users can suspect that Google have privacy problems if Mozilla prefer to switch  \n",
    "If users from Mozilla will not go to google services like Google Map etc - it could make worse relevance  \n",
    "of quality of this services - users could go to competitors services.  \n",
    "Also google search engine depends on user traffic - so it should be estimated problems with engine if  \n",
    "google will be not default search engine in Mozilla\n",
    "  \n",
    "---\n",
    "<u>10.5 Linkedin</u>  \n",
    "Linkedin Feed. What metric would you use to track engagement? How would you improve this metrics?  \n",
    "  \n",
    "**CQ**  \n",
    "- How Feed works now, what info included\n",
    "Lets consider: follow posts, recommended posts & events, ad\n",
    "- For what segment we could check engagement: influencers, ordinal followers, companies?  \n",
    "- what actions can now users do in feed? Make posts, go to events, follow users\n",
    "- whats typical behaviour of target user segment - how much users make target actions? \n",
    "  \n",
    "**Solution**  \n",
    "Engagement define how much user invole in using functionality of this feature. More engagement users has  \n",
    "greater retention and better monetisation potential. Engagement metric should be short term like  \n",
    "good proxy to retention.  \n",
    "We have cluster of users who start use linkedin intensive when need to find job. Better retention =  \n",
    "better chance to use monetisation product etc.  \n",
    "  \n",
    "First level of engagement is spending more time to research useful information.  \n",
    "Second level is conversion to some target action - example follow, make comment, post etc.  \n",
    "We could check on historical period which correlation is better with  \n",
    "Also could check correlation with this engagement actions to chance to answer on apply (conversation)  \n",
    "  \n",
    "To increase engagement level (ex. lets make conversion to comment/likes/followings) we could:  \n",
    "- make tests with better recommendations \n",
    "- tests with design to suggest on Feed more relevant companies etc\n",
    "\n",
    "**Book info**  \n",
    "High-level metrics of engagement ofcourse is MAU, DAU etc - how often active users in service.  \n",
    "You can create scored metrics like:  \n",
    "- content consumption score (likes, views, event checks etc)  \n",
    "- content creation score (posts cnt, comments, sharings etc)\n",
    "\n",
    "To watch how to improve except experiments you could:\n",
    "- check important features that affect engagement metrics and try to improve it (check with rand.forests example) \n",
    "- check competitors, what kind of features do they have released\n",
    "\n",
    "---\n",
    "<u>10.6 Lyft</u>  \n",
    "You try to understand if new UI rider app increase riders taken cnt. How to split groups in about tests and  \n",
    "be ensured that you have balanced groups?\n",
    "\n",
    "**Solution**  \n",
    "Main problem is network effect. If we increase test-riders conversion - we increase orders in drivers and  \n",
    "it could affect control-riders activity too. We could use metric like riders cnt per user who open app.  \n",
    "We couldn't use switchback time here cause user will see changing UI and it should affect him bad.  \n",
    "We could use geo splitting for better to separate groups - we could choose group config in control and test  \n",
    "checking that in A/A tests validation all will be good (control I type error).  \n",
    "\n",
    "---\n",
    "<u>10.7 Amazon</u>  \n",
    "If you plot avg revenue per seller on Amazon - what would the shape of distribution?  \n",
    "  \n",
    "**CQ**  \n",
    "Lets define revenue here. Revenue = income - amazon tax?  \n",
    "Should we check all countries, so we could use US dollar as main currency?  \n",
    "Also we consider all segments of amazon sellers like = big companies & also smb.  \n",
    "Also abut avg - what period we use - avg for lifetime? For new users we will have small revenue  \n",
    "respect time of their service living.\n",
    "\n",
    "**Solution**  \n",
    "In any marketplaces we have very big companies that have huge revenue tail - so thats outliers.  \n",
    "So, i guess we have long right tail distribution.  \n",
    "If we have clearly separate seller segments - we could have several max of this distribution.  \n",
    "Near local max it could be normal distribution cause very much sellers - so CLT.  \n",
    "New users = close to zero maximum for that segment.  \n",
    "\n",
    "**From book**  \n",
    "In many business main distribution is Pareto, where 80% of revenue generates about 20% of users.  \n",
    "So we have super right skewed distribution with small cnt of big-revenue users and large cnt of small rev users.  \n",
    "  \n",
    "---\n",
    "<u>10.8 Facebook</u>  \n",
    "Whats posts Facebook should remove beside those who needed to be removed according by law? What features could you use to identify this posts  \n",
    "\n",
    "**Solution**  \n",
    "We should remove posts which make negative reputational and engagement effect to FB users.  \n",
    "We consider that legally we should remove: scam, posts with violence etc.  \n",
    "  \n",
    "Also we could use some desinformation posts (example, again COVID) - which could hurt people with  \n",
    "using this wrong information. It could be political, pseudo-medicine, etc posts.  \n",
    "  \n",
    "Trade-off: we will loose audithory which are dedicated with this wrong ideas; also have reputational risks  \n",
    "like strict censorship platform.  \n",
    "  \n",
    "For reveal posts with desinformation we could use ML models, which will be trained from examples created by  assesors. It could be classifier with several rarget types of posts - example LLM or boosting.  \n",
    "  \n",
    "**From book**  \n",
    "False positive and false negative cases when you use your model to classify posts  \n",
    "FP = posts really not bad, but model hide it - so people colud post less or deactivate accounts etc.  \n",
    "FN = bad posts not deactivated so it affect users with negative.  \n",
    "  \n",
    "---\n",
    "<u>10.9 Amazon</u>  \n",
    "Amazon books: books with more complete author profiles sells more.  \n",
    "Team make autofill profiles with Wikipedia info, but sales doesnt changes - why?  \n",
    "\n",
    "**Solution**  \n",
    "1) Correlation not causation. Example, more famous authors have better selling books and  \n",
    "they also better fill  their profile - but real factor which affect book salling is \"famous\"  \n",
    "\n",
    "2) Do you auto-fill actually:\n",
    "- part of information that have correlation. Maybe text dont have but author photo have and you match just text  \n",
    "- enough percent of profiles (if there are many unmatched profiles - it could give not enough shift)\n",
    "- accuracy of mathing (is it usually exact right author information - should validate it)  \n",
    "  \n",
    "---\n",
    "<u>10.10 Snapchat</u>  \n",
    "We see overall 5% decrease in DAU - trend that had been consistent over the week. How to determine a reason?  \n",
    "\n",
    "**CQ**  \n",
    "Is it 5% decrease comparing prev week or YoY? Lets tell about WoW effect. \n",
    "What is active users in Snapchat? User who open app during the day.  \n",
    "\n",
    "\n",
    "**Solution**  \n",
    "First of all - is it significant decrease? (lets say, yes)  \n",
    "  \n",
    "We can check three type of reasons:  \n",
    "internal:\n",
    "- logging problem, check if all okey\n",
    "- any releases before week start (check increase in segments: platform, devices, user_type etc)  \n",
    "- marketing activity (start/end ad campaigns)\n",
    "- any bugs in pipeline (check funnel; example, problem with push notifications etc)\n",
    "  \n",
    "external:\n",
    "- is any competitors activity (TikTok, Telegram etc) in your market?\n",
    "- is any holidays, world events that could affect, politics regulations\n",
    "- seassonable (check trend with previous years)\n",
    "\n",
    "---\n",
    "<u>10.11 Pinterest</u>  \n",
    "You ship new ranking algo. What metrics you'll use to measure impact.  \n",
    "  \n",
    "**CQ**  \n",
    "Check some algo details. Is it feed ranking algo? Is any segments (users, geo, ...) where algo works?  \n",
    "Lets assume - all site, main feed, algo after you put query.  \n",
    "What main purpouse of algo, what metric we optimise? Lets: adding in favorite.  \n",
    "\n",
    "**Solution**  \n",
    "We have AARRR framework = acquisition, activation, retention, referral, revenue  \n",
    "If algo touch unlogged users - activation metrics = percent of users with sign in.  \n",
    "Engagement metrics: conv and avg cnt of adding ideas in favorites per session/users.    \n",
    "Monetisation metrics: if we use ad = time per session; ad CTR; CTR to partners.  \n",
    "According purpose: lets consider adding favorites (more engagement), but guardrail: ad, activation.  \n",
    "Also, if we have different segments: could check individually.  \n",
    "  \n",
    "**From book**  \n",
    "Check if algo have UI changing moments  \n",
    "Also check main company mission goals and connection of algo potential impact and goals.  \n",
    "(!) user search cnt and user time spend is problem metrics: bad algo could tend to make search experience worse.  \n",
    "But user spend time could be guardrail metric if it depends on ad.  \n",
    "\n",
    "---\n",
    "<u>10.12 Netflix</u>  \n",
    "sci-fi TV shows have less total watch time than other similar categories.  \n",
    "What metrics should use to determine: if people are not interested in that category  \n",
    "OR category okey but content bad. Another words: demand or supply problems.  \n",
    "  \n",
    "**CQ**  \n",
    "Lets determine category which we discuss = TV shows.  \n",
    "So, we assume that current watch time is a problem comparing example \"late night shows\", \"cooking shows\" etc.  \n",
    "Total watch time = total time during **equivalent** period for all comparing categories (so, its not new)  \n",
    "Also, are we have enough content of sci-fi on platform? So, its not a problem of lack of supply.  \n",
    "  \n",
    "**Solution**  \n",
    "So, we assume that we have equivalent potential watch time supply comparing other categories.  \n",
    "watch time (per period) = watch_users_cnt * watch_time_per_user  \n",
    "  \n",
    "If users are not interesting with sci-fi we could check it in small watch user cnts  \n",
    "\n",
    "We should check funnel: is it simple to find this part in platform + recommendation issues.  \n",
    "Is new users have equal way to check this category comparing similar categories?  \n",
    "\n",
    "If conversion from view category to start watching is low - maybe we have demand problem.  \n",
    "Also, we could have bad images, posters with low conversion = thats mean content problem  \n",
    "We could check search cnts - where users try to find shows from this category.  \n",
    "  \n",
    "Content quality problem will be if we have problem with metrics like:  \n",
    "watch_time_per_user, retenetion to watch in this category, proxy-metrics like like/dislike, comments.  \n",
    "\n",
    "**From book**  \n",
    "Could check also segments: maybe in some countries we don't have normal translation or other - content problem.  \n",
    "We could use external benchmarks - what are engagement metrics (conversion from start to finish series)  \n",
    "in this  category in market and what is our results comparing it.  \n",
    "\n",
    "---\n",
    "<u>10.13 Apple</u>  \n",
    "You have data on millions customers + purchases in physical restores.  \n",
    "How customer segmentation increase store sales performance? How to segmentate offline customers?  \n",
    "  \n",
    "**CQ**  \n",
    "Do we recognise users in store, checking his history and make individual suggestion?  \n",
    "If yes, what communication channels do we have: user mails, phones, just next offline visit moments?  \n",
    "Its define what kind of actions could we make based on purchase information.  \n",
    "Do we have any metadata of users like age, sex, geo, family accounts?  \n",
    "Could we customise pricing decisions here to use segmentation for increasing performance?  \n",
    "  \n",
    "**Solution**  \n",
    "Having offline purchases we can extract:  \n",
    "1. RFM segmentation = recency; freq; monetisation.  \n",
    "2. sex estimate (male/female; if we have names and info lke color about purchases)\n",
    "3. geo (knowing geo of stores)  \n",
    "\n",
    "Based on some purchases on train-period we could predict what users prefer to buy next.  \n",
    "And we could suggest it with next user visit in the store (with or without discount), or by mail.  \n",
    "Example if user by iphones, and buy it frequently - we could predict that he will want to  \n",
    "switch on next model. So we could change loyalty program with discounts or bundles.  \n",
    "  \n",
    "RFM.  \n",
    "If we have highly engaged users - we could suggest other eco-system products like subscriptions,  \n",
    "bundles, additional purchases.  \n",
    "  \n",
    "We could try to check from purchases if its family-person, who example buy several iphones or  \n",
    "other gadgets in short time. We could customise recommendations for this segment.  \n",
    "\n",
    "For person who update his gadgets (like iphones, macbooks etc) every year or couple years,  \n",
    "we could suggest to subscribe on info events, or use info like: if you want to update  \n",
    "your model you could check this new models, with relevant features etc.  \n",
    "\n",
    "**From book**  \n",
    "This analysis should be complemented with market-research cause we don't know how new non-apple users  \n",
    "could react on our new store-modifications which based on purchase story.  \n",
    "We also could use information about prev purchases as estimate of user-level (like pro or beginner etc).  \n",
    "Also, we could use K-means segmentation to define most freq customers and then describe segments and work with it. \n",
    "\n",
    "---\n",
    "<u>10.14 Facebook</u>  \n",
    "70% FB user on IOS also use instagram; 50% FB user on Android use Instagram - why we have this imbalance?  \n",
    "  \n",
    "**CQ**  \n",
    "Definition: user on FB and Instagram = user who have accounts on this platforms?  \n",
    "do we talk about all users in FB, not specific countries?  \n",
    "do we have functional or design differences with Insta version on android and ios?  \n",
    "do we have differences in integration between fb and instagram in this platforms?  \n",
    "Do we have same differences in all countries?  \n",
    "  \n",
    "**Solution**  \n",
    "Main targets of this platforms: fb is about communication, also checking usefull events and news, work contacts.  \n",
    "Instagram is more about sharing your life experience with photos, videos etc.  \n",
    "  \n",
    "It could exists hidden factors: people with this factors both can use more android and use less instagram.  \n",
    "  \n",
    "Some hypothesis:  \n",
    "1. Differences in engagement pipeline. In IOS is better working push to create instagram acc from fb  \n",
    "1.2 Quality of instagram app on ios/android. Check engagement flow.  \n",
    "1.3 Quality of camera - is it instagram_% depend on android phone models? some users prefer cheap phones  \n",
    "with bad camera for some reasons and thats why don't need to use instagram\n",
    "2. people who like create live content both like to buy iphone & create instagram. We should check  \n",
    "(UX research) that significant part of android-fb users don't have other content sharing platforms at all.  \n",
    "3. in some countries people could use mostly android and also don't use instagram cause some local alternatives.  \n",
    "But they still use fb as universal platform for communication or making news. this segments can make bias  \n",
    "4. age bias: there are many more old people who could use fb for communication, prefer android and don't have insta\n",
    "5. sex: women maybe could prefer more to use ios & more instagram in same time.    \n",
    "\n",
    "So, i would check if i have significant imbalance in some of this segments:  \n",
    "age, geo, sex, markets with strong competitors.  \n",
    "Also i would check funnel to find out a product integrity if bias in all of this segments.  \n",
    "\n",
    "---\n",
    "<u>10.15 Capital One</u>  \n",
    "how would you assess stickiness of CO quicksilver credit card?  \n",
    "  \n",
    "**CQ**  \n",
    "What do we mean stickiness here (look in solution)  \n",
    "more details about quicksilver creadit card & Capital one mission\n",
    "  \n",
    "**Solution**  \n",
    "Lets define what is stickiness: its how service engage user to repeat use it frequently.  \n",
    "Example, one of the stickiness metric is r = DAU/MAU. When r raise - many people use product constantly.  \n",
    "  \n",
    "Here, we have credit card product. Best option is when people use this card parmanently so make payments on them.   \n",
    "Activation: user use credit card first time. I think if we suggest product for every day (paying for food,  restaurants etc) - we could use DAU/MAU ratio.  \n",
    "\n",
    "If there is other expected frequency - could use MAU/YAU.  \n",
    "Also we could track other freq metrics like: how often (many months,weeks, days) per year user use card.  \n",
    "If we calculate with payment periods (open period - close period) - we could check which percent of this  \n",
    "periods per year were activated by user who start use credit card.  \n",
    "  \n",
    "**From book**  \n",
    "Another proxy way is to check month-month retention. How much users return after X months of activation.  \n",
    "More common metric which depend on stickiness is cum_payment_sum (how much cash user spend with credit card)  \n",
    "\n",
    "---\n",
    "<u>10.16 Google</u>  \n",
    "You work in Youtube Premium = ad free version + youtube music. Launch in few countries, how to determine price?  \n",
    "  \n",
    "**CQ**  \n",
    "Do i have already experience and info about launch this product in other countries?  \n",
    "Is youtube music already launched in target countries? (separate of premium)  \n",
    "Could we make pricing ab tests on small groups of users to measure elastity?  \n",
    "  \n",
    "  \n",
    "**Solution**  \n",
    "Lets consider some country X. I already have youtube music price in this country = Y.  \n",
    "I could check how much one avg free user could bring from ad (ad LTV for one subscribe period)  \n",
    "If i suggest youtube premium - in this service will move some users which already listen music and not.  \n",
    "I could use other countries benchmark to estimate this conversions.  \n",
    "\n",
    "Also bundle users will be more engaged in service -> more views ->  \n",
    "more creator loyalty -> more free user views -> more ad.  \n",
    "We could use metric tree to estimate additional cross-ad revenue stimulated by bundled users.  \n",
    "  \n",
    "YT-music users:  \n",
    "control = music LTV + ad revenue\n",
    "test = bundle LTV (churn rate will be smaller) + cross-ad revenue (cause more engagement)  \n",
    "delta = our effect  \n",
    "\n",
    "Free users:  \n",
    "control = ad revenue  \n",
    "test = bundle revenue + cross-ad revenue\n",
    "\n",
    "Competitor analysis: suggest relevant pricing comparing market.  \n",
    "Also we could do UX market research to feel normal price range for stable demand.   \n",
    "  \n",
    "**From book**  \n",
    "Main CQ question: what goal of pricing? Should we capture market or should have sustainable unit economic?  \n",
    "For cost calculation: we should calculate localisations cost, local music license cost for YT\n",
    "1. Cost plus pricing. Cost of YT music + extra cost = func(localisation costs, ad, ad revenue lost)  \n",
    "2. Value based pricing. Pricing based on user perception of price - interviews and market research.  \n",
    "3. Competitor based pricing. Check how much more valuable YT premium than competitors - calculate relevant price. \n",
    "\n",
    "We could actually blend all of this strategies together to perfect pricing.  \n",
    "Also could try AB testing.  \n",
    "\n",
    "---\n",
    "<u>10.17 Twitter</u>  \n",
    "Should Twitter add FB style emoji reactions to tweets?  \n",
    "  \n",
    "**CQ**  \n",
    "What target metrics could we drive in Twitter? Do we have goal of this modification?   \n",
    "Check current feedback structure on tweets:  \n",
    "- likes cnt \n",
    "- comments \n",
    "- reposts\n",
    "\n",
    "What kind of ranking algo we have that depend on likes cnt? How we use current like-mechanism?  \n",
    "  \n",
    "  \n",
    "**Solution**  \n",
    "Model: not big cnt of influencers with big number of followers. Also small and private communities.  \n",
    "\n",
    "Emoji positive moments:  \n",
    "1. drive engagement - people like to share color feedback, we could increase cnt of tweets with feedback\n",
    "2. could get more diversity information about users relation to the posts\n",
    "\n",
    "Emoji negative for Twitter moments:  \n",
    "1. it could affect ranking algo which rely on binary like-logic\n",
    "2. it could decrease cnt of comments \n",
    "3. negative emojies could frustrate content creators, which affect their activity.  \n",
    "For this reason Youtube hide dislike button. FB not so content creator oriented as Twitter.  \n",
    "4. consumer phones need more resources to support emoji - it could affect speed of feed search.  \n",
    "  \n",
    "Based on YT experience i think it not a good idea add emojii in influencer-oriented network.  \n",
    "One of trade-off decision is to allow tweet authors to choose type of possible emoji like in Telegram.  \n",
    "We could make ab test to measure increasing of engagement level and creator patterns.  \n",
    "Also we should analyse all potential problem of current ranking algorithm and how we will affect  \n",
    "Twitter feed performance in user phones.  \n",
    "\n",
    "**From book**  \n",
    "Use research team and parse some comment-patterns to check if users try to express more complicated emotion  \n",
    "that just like (example, haha, lol patterns etc)\n",
    "\n",
    "---\n",
    "<u>10.18 Slack</u>  \n",
    "What metrics would you measure for engagement of Slack. How to tell early if engagement was declining?\n",
    "\n",
    "**CQ**  \n",
    "What engagement metric uses in Slack. Could we use like cnt of actions  \n",
    "(posts, comments, channels, integrations) per company per period of time?\n",
    "\n",
    "**Solution**  \n",
    "Slack = app/desktop platform for communication mostly in work companies (with treds, channels etc.)  \n",
    "Main user actions: comments, channels creation,   \n",
    "  \n",
    "Engagement = how active user use slack functionality every day/week etc.  \n",
    "Its better to use week step minimum to take into account weekends factor.  \n",
    "Engagement decrease = early predictor of churn to using slack, staying on paid subscription etc.  \n",
    "\n",
    "We can track user metric like: avg per user cnt of comments/channels creating/adding to channels but  \n",
    "if in companies new users will get involved into slack - it could be dilution  \n",
    "  \n",
    "We could use cohort analysys - cnt of target actions per company in cohorts, which already use slack.  \n",
    "New cohorts could have weaker engagement and will increasing in time.  \n",
    "If later cohorts after N months start to use slack weaker that cohorts before it could be a signal.  \n",
    "  \n",
    "Also we can check one cohort and how activity level changes in time - should be stable or increasing  \n",
    "(cause more users signed in slack, more target actions per one company making)  \n",
    "  \n",
    "To get earlier understanding that engagement will declined we could:  \n",
    "check NPS metrics and FEARs - maybe we have some problems with functionality  \n",
    "check funnel metrics: cnt of slack opens per day (DAU), cnt of slack messaging per day  \n",
    "DAU/WAU, DAU/MAU could also demonstrate stickiness of product that important for engagement.  \n",
    "  \n",
    "**From book**  \n",
    "Most important metrics are - active users cnt and number of sent messages  \n",
    "Its good not to use ratio metrics but also absolute like general DAU etc = but in this way we  \n",
    "could mix engagement and acquisition effect, which depend on marketing example.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ace data science interview - case exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>11.1 Citadel</u>  \n",
    "you wanted to estimate physicall store sales for publicy traded retail chain in US.  \n",
    "have access to third-party foot trafic data for each store from anonymized GPS from 10 million mobile phones.  \n",
    "how to use foot trafic dataset to predict chain's in-store revenue.  \n",
    "  \n",
    "**CQ**  \n",
    "1. what do we have in data: date, store_id, device_id? could we check if one device visited several stores?  \n",
    "2. data completness: \n",
    "We get useful geo-information in US, so we could assume that this is full trafic, provider could give us  \n",
    "data about almost any phone with switched-on GPS. We could try to check if 10 million is enough cnt of users  \n",
    "who use this retail market (depend of company share and period)\n",
    "3. this is public retail company so we have information about company revenue from open source  \n",
    "Also we could use public revenue prediction for future periods (quarter, year)  \n",
    "PS. do we need to predict in-store revenue in period which we could check in general from public reports?  \n",
    "if not we could use this reposrts for additional predict of general company revenue.\n",
    "4. do this company have online revenue, could we separate it, is it possible to get online order in shop or  \n",
    "we could link almost every visit in shop as purchase act?\n",
    "\n",
    "**Solution**  \n",
    "Okey, so we have data like: store_id, date, device_id  \n",
    "we could calculate which share of traffic in-store relative common value.  \n",
    "== Avg check estimation ==  \n",
    "it works if we assume that in every store is same avg check. Maybe it could depend of shope type.  \n",
    "we could use google review information to estimate avg check size, we could make ux research about it.  \n",
    "So we could try to estimate avg purchase sum and use visit info to estimate or we could use total revenue reports  \n",
    "if we have this one and could separate stores revenue of other revenue sources.\n",
    "  \n",
    "**From book**  \n",
    "important CQ:  \n",
    "what main goal of revenue prediction - say, its about investment decision  \n",
    "do we want to predict total in-store revenue, not each store - correct  \n",
    "also, we want to predict revenue in future, we don't know actual revenue, so we want to predict traffic first  \n",
    "we want to calculate future quarter-to-quarter revenue.  \n",
    "  \n",
    "solution ideas:  \n",
    "1. we normalised visit data as user_cnt per quarter - to predict next quarter cnt and revenue as result\n",
    "2. we could use simple models like linear regression to predict visits  \n",
    "3. to check sample bias of model we could compare night time gps location (like home people location) with  \n",
    "info about US population and check from which states, regions we have better cover of GPS info, determine avg  \n",
    "income of people who visit in store (knowing region statistic)\n",
    "\n",
    "---\n",
    "<u>11.2 Amazon</u>  \n",
    "You are designing system whose purpose to recommend what shows user should watch on Amazon Prime Video. What data and techniques would you use?  \n",
    "  \n",
    "**CQ**  \n",
    "What metrics are most important here in the system - could we talk about  \n",
    "high engagement rate and good retention  as result?  \n",
    "Should we take into account high load property of this system? (assume not, just talking about recommendation). \n",
    "Do we need to discuss about mvp decision or more complex, another words do we depend of any time frame?  \n",
    "\n",
    "**Solution**  \n",
    "Amazon Prime = Netflix competitor, system where user can watch relevant content for subscription.  \n",
    "We want to recommend cocntent, which maximise user engagement metrics like conversion from first to last episode,  \n",
    "avg watching time duration, avg frequency of visiting Prime during week, month.  \n",
    "  \n",
    "Assume we work with users who already have time on prime and watch some shows there.  \n",
    "We could create embeddings on each show (some descriptin vector) and make clusterisation -  \n",
    "if user watch show X and have positive feedback (reaction, good engagement metrics), we could  \n",
    "recommend show Y which are close to this in embedding space. All embeddings could calculate offline for  \n",
    "better speed of recommendation at moment. Could use batch K-means for clusterisation.  \n",
    "  \n",
    "**From book**  \n",
    "Main method is \"Collaborative filtering\":  \n",
    "- user-based: we find users with same like-patterns and recommend to user same content as to other\n",
    "- item-based: we find items wich links to other items like \"users also like it\"\n",
    "\n",
    "Alternative way = based filtering = when we use K-means to find similar items and if user choose and  \n",
    "give like to one item - we could recommend simmilar; here we use some content information features  \n",
    "We could mix this methods in hybrid system.  \n",
    "\n",
    "---\n",
    "<u>11.3 Airbnb</u>  \n",
    "You are modeling yearly revenue of new property being listed. What kind of features would you use?\n",
    "  \n",
    "**Solution**  \n",
    "So, we assume that property beign listed and during the year it could rented several times and we want to predict yearly revenue that we get from this property.  \n",
    "We get revenue as percent of total customer payment for this property. So we need to predict how many  \n",
    "cash flow would generate this property.  \n",
    "  \n",
    "We know historical data of similar properties for prediction.  \n",
    "We could use features about property:  \n",
    "- geo (region, distance to the center)\n",
    "- is it whole property or separate room etc\n",
    "- has it wifi, ciuisine, etc\n",
    "- schedule of renting (user could reserve some time slots for renting or not)\n",
    "- pet friendly etc\n",
    "- of course price which owner create\n",
    "\n",
    "Features about owner:  \n",
    "- how many years on platform (could impact on sustainable behaviour)\n",
    "- avg rating\n",
    "- probability of cancelling\n",
    "\n",
    "We could use some tree regression methods like XGboost, if we have enough data and check about overfiting.  \n",
    "\n",
    "**From book**  \n",
    "Also, we could add local market features:  \n",
    "rating of nearby places, prices of nearby (to idintify is it high or low current price)\n",
    "\n",
    "---\n",
    "<u>11.4 Walmart</u>  \n",
    "How would you build algorithm to price products sold physically at Walmart stores?  \n",
    "\n",
    "**CQ**\n",
    "What main goal for this algorithm? lets say, we want to increase total revenue  \n",
    "How often could we change price, get information about demand?  \n",
    "What could be pricing time step - example once per week or for new goods supply.  \n",
    "\n",
    "**Solution**  \n",
    "We could optimise utilisation of products in store.  \n",
    "Example, some kind of product have bad demand - decrease price, or vice versa.  \n",
    "For each product we also have natural lower price limit (economics should be > 0).  \n",
    "Also we have lifetime of product (some live long and some in short-term)  \n",
    "\n",
    "For each dt (week, month?) we could collect data like:  \n",
    "product_id, supply_cnt, sold_cnt, price_per_unit  \n",
    "  \n",
    "We need to minimise cnt of products with out of life and maximise revenue.  \n",
    "We could use cohort analysis:  \n",
    "- predict price elastisity (sold_cnt_per_period(price_per_unit))  \n",
    "- forecast cohort ltv based on: predicted sold cnt * price  \n",
    "- for each product_id lifetime is different (short-long term)  \n",
    "\n",
    "---\n",
    "<u>11.5 Accenture</u>  \n",
    "You want to help major hotel chain analyze what people say about brand in Facebook, Tw, Reddit.  \n",
    "Why it could be useful and how to do it?  \n",
    "  \n",
    "**Solution**  \n",
    "It could be helpful for several reasons:  \n",
    "- check some hotel mistakes, customer pain points - to solve it and improve quality\n",
    "- use this information in marketing to underline strongest pattern of brand in ad  \n",
    "- understand your target segment - what persona use hotel (young generation, businessmans, etc)\n",
    "- understand for what \"job\" people hire hotel (tourism, rest during travel etc) - it could impact decision about in what places you could open new hotels  \n",
    "  \n",
    "First of all your need to get text data about this brand form this social nets.  \n",
    "You could buy it from third-party companies, use crawler to parse pages from communities about hotel or  \n",
    "search pages by tag with this hotel. You could search through branches wich contain hotels info in title.  \n",
    "  \n",
    "Next you could use LLM or some linguistic algo's to reveal emotional context of information,  \n",
    "classify it for some main ideas of comments (example to pain points)   \n",
    "You could use some embeddings and make segmentation for closest statements about hotel, then to identify what  \n",
    "kind of segments do we have in this problem\n",
    "  \n",
    "**From book**  \n",
    "We should check it before in CQ!  \n",
    "what content we want to analyze (reviews, comments, ...), do we already have data or we should get it?  \n",
    "Also its important to analyze info about hotels cause check public opinion about hotels through nets -  \n",
    "maybe we should more focus on answering about questions in social nets, explain some moments about business.  \n",
    "  \n",
    "Text preprocessing issues before use NLP models:  \n",
    "- text encoding (приведение в одну систему типа utf-8, токенизация, удаление спецсимволов)\n",
    "- stripping away html-tags and other meta-info \n",
    "- stemming / lemmatization (быстрое/медленное упрощение слов вроде: \"better\" → \"bett\"/\"good\")\n",
    "- vectorization context (making embeddings)\n",
    "\n",
    "---\n",
    "<u>11.6 Facebook</u>  \n",
    "You build Fb friend recommendation product \"people you may know\" (PYMK). How to do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
