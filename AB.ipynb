{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "warnings.filterwarnings('ignore')  # Игнорировать все предупреждения (не рекомендуется в продакшн-коде)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from causalinference import CausalModel\n",
    "from scipy.stats import chisquare\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from causalinference import CausalModel\n",
    "import help_tools as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбор статей и книг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Avito Habr: лайфхаки по улучшению АБ тестов  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://habr.com/ru/companies/avito/articles/571094/  \n",
    "https://habr.com/ru/companies/avito/articles/571096/  \n",
    "https://habr.com/ru/companies/avito/articles/590105/\n",
    "\n",
    "---\n",
    "1. Для АА-валидации критериев можно использовать исторические данные с метрикой (например, выручка), поделив  \n",
    "ее на множество сегментов (например, группы товаров/регион/сайт итд): каждый сегмент = АА тест с реальной метрикой.  \n",
    "Каждый такой тест можно превратить в AB - симулируя смещение одной из веток. Моделируем аплифт, сохраняем real std.\n",
    "2. При фильтрации выбросов корректно убрать топ N% наиболее крупных клиентов - трешхолд общий для теста и контроля.  \n",
    "outlier_threshold = np.quantile(np.concatenate(control_before, test_before), 0.99)  \n",
    "Так избавляемся от смещения если оценивать его по control/test выборкам.\n",
    "3. При анализе AB относительные дов. интервалы типа 10+-5% нагляднее чем абсолютные или расчет p_value.  \n",
    "Аналогично при расчете чувствительности можно вместо MDE использовать оценку ширины дов. интервала.  \n",
    "Ширина дов. интервала разности средних двух выборок схожих дисперсий half_w = sqrt(2) * MDE.  \n",
    "4. CUPED/CUPAC: берем пред-тестовый датасет - обучаем на нем модель, предсказываем на тестовых участниках  \n",
    "метрику -> оцениваем снижение дисперсии (aka дов интервалов). Меняя модели и гиперпараметры - подбираем оптимальный Y_forecast.  \n",
    "PS. нормируем признаки для удобства - StandardScaler.  \n",
    "5. Для фильтрации признаков, на которых идет обучение для CUPAC - жадный алгоритм добавления/удаления признаков (например, SequentialFeatureSelector из библиотеки scikit-learn на Python). Более быстрые алгоритмы - на основе  \n",
    "feature importance (SelectFromModel из библиотеки scikit-learn на Python). Можно также использовать add-del  \n",
    "функциональность - добавляем/удаляем признаки пока не получим максимального улучшения качества модели "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Kohavi book: Trustworthy online controlled experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Randomized controlled experiments are the gold standard for establishing **causality***\n",
    "\n",
    "<u>When we can use AB testing</u>\n",
    "\n",
    "- there are units (ex. users) that can be assigment to variants\n",
    "- there are enough users for testing (>10**3)\n",
    "- key metric (OEC) could be evaluated and have sensitivity\n",
    "- changes are easy to make\n",
    "\n",
    "**Best practise**: using AB testing together with Ajile software development process & Lean\n",
    "AB testing can be automated and using together with CI/CD processes \n",
    "Important target - to make one iteration from delevopment to testing fater\n",
    "In MSFT only 30% of test’s successful. In well-optimized domains like Google rate ~ 10-20%\n",
    "Most of your work will be rejected - build your process according this point\n",
    "`\"If you have to kiss a lot of frogs to find a prince, \n",
    "find more frogs and kiss them faster and faster\"`\n",
    "\n",
    "h_0: hypothesis that control and experiment values are the same\n",
    "p_value: the probability of getting this or more extreme observed result if H_0 is True \n",
    "\n",
    "<u>Internal validity</u>\n",
    "\n",
    "There is a trustworthiness of conclusions on current data \n",
    "- sample ratio mismatch problem (health checks)\n",
    "- statistical tests suitability (AA-validation, p_val pick problem, filter outliers)\n",
    "- residual effect (SRM ⇒ when test was cracked at first and we have affected users)\n",
    "- SUTVA (units are independent and also control/test are separate from each other)\n",
    "\n",
    "<u>External validity</u>\n",
    "\n",
    "Is it possible to apply test results to more general cases.\n",
    "\n",
    "- is it okey on new regions, platforms etc. (generalisation)\n",
    "**Solution**:  rerun test in new condition\n",
    "\n",
    "- long term effects (can we generalize conclusion across time)\n",
    "   long term ⇒ primacy (old) and novelty (new) effects\n",
    "\n",
    "**Solution:** check treatment effect with coinfidence interval across the time\n",
    "Also, is possible to fix cohort of users coming in exp first days and track effect(time)\n",
    "\n",
    "<u>Segmentation </u>\n",
    "(additional sources on page 122)\n",
    "If segm_1 goes up and segm_2 goes up - (total_1_2 can goes any direction)\n",
    "Because of moving users between segments\n",
    "\n",
    "If segments area different: s1_control, s2_control, s3_exp, s4_exp - it could \n",
    "be Sympson’s paradox (`a/b<A/B and c/d<C/D but (a+c)/(b+d)>(A+C)/(B+D)`)\n",
    "Example: 44/700 & 46/700 VS 75/1200 & 17/300\n",
    "\n",
    "Be careful aggregating data collected at different percentages\n",
    "Both cases is about **non representative** groups in control and experiment.\n",
    "\n",
    "<u>Metrics taxanomy</u>\n",
    "\n",
    "**Goal metrics** - metrics for your company mission. Why does your product exist\n",
    "At first, you can articulate your main goal in words. There are small set of long term metrics.\n",
    "\n",
    "**Driver metrics** - surrogate, predictive metrics. They have good sensitivity, short term behaviour.\n",
    "There is not about what is success, but about way (action) to achive this\n",
    "Example: AARRR, HEART, funnels frameworks\n",
    "\n",
    "**Guardrail metrics** - internal validity check metrics and system protection metrics.\n",
    "We don’t want to drop this metrics improving goal and driver ones\n",
    "\n",
    "<u>Metrics evaluation</u>\n",
    "\n",
    "Important part of ab-evaluation of metrics - to proove causality between driver metrics and goal metrics (ex. LTV could been evaluated periodically to check if errors stay small)\n",
    "\n",
    "There are few points how to establish causal links between metrics:\n",
    "\n",
    "- use surveys, focus groups e.t.c to check whether they all point in same direction\n",
    "- use observational data (logs e.t.c) to check your hypotheses\n",
    "- check whether similar validation is done at other companies\n",
    "- conduct an experiment with primary goal of evaluating metrics\n",
    "- use historical experiments to check for sensitivity and causal alignment\n",
    "\n",
    "It is not enough to be agile and to measure\n",
    "You must make sure your metrics guide you in the right direction\n",
    "\n",
    "*Literature*:\n",
    "1) Spitzer, Dean R. 2007. Transforming Performance Measurement: Rethinking the Way We Measure and Drive Organizational Success. AMACOM\n",
    "2) Parmenter, David. 2015. Key Performance Indicators: Developing, Implementing, and Using Winning KPIs. 3rd edition. John Wiley & Sons, Inc\n",
    "3) McChesney, Chris, Sean Covey, and Jim Huling. 2012. The 4 Disciplines of Execution: Achieving Your Wildly Important Goals.\n",
    "\n",
    "<u>Metrics for experimentation</u>\n",
    "\n",
    "Not all metrics that are used for business reporting purposes are appropriate for experimentation\n",
    "\n",
    "Some requirements for good experimentation metrics:\n",
    "\n",
    "- measurable (actually, with numbers eq)\n",
    "- sensitivity - you can detect meaningful changes during necessary testing period\n",
    "- attributable (you can assign this metric to testing variants = branches)\n",
    "\n",
    "<u>Overall evaluation criteria</u>\n",
    "\n",
    "In AB-tests you need to optimise several metrics simultaneously (ex. monetary and engagement) \n",
    "OEC = numerical model of trade-offs between different metrics (ex. FICO-score on risk card)\n",
    "\n",
    "Assume, you have N metrics: metric_1, … metric_N\n",
    "metrics → normalisation to {0;1} range → OEC = weighted sum (w1 * metric1 + w2 * metrics2 …)\n",
    "\n",
    "Next step - minimise the number of metrics, using prioritisation. Good number is ≤ 5\n",
    "It emphasize you on main metrics and helps with multiple comparison problem.\n",
    "\n",
    "*Example: Amazon’s optimisation of sending emails to customers*\n",
    "OEC = sum(Revenue_customer - unsubcribes_count * Lifetime_loss) / N_customers\n",
    "revenue - profit with email using\n",
    "unsubcribes_count - count of users who delete subcription because too much emails\n",
    "lifetime_loss -  LTV of churn users who delete subcription\n",
    "\n",
    "<u>Complementary and Alternative Techniques to Controlled Experiments</u>\n",
    "\n",
    "UX interviews, surveys, focus groups, logs analysing - methods to understand customers problems. You can use this researches to generate more ideas for ab testing, create causalities hypothesis about metrics e.t.c\n",
    "\n",
    "<u>Observational Causal Studies</u>\n",
    "(more details in Stats/causal inference)\n",
    "\n",
    "Exp_effect = Outcome_for_treated - Outcome_for_untreated = \n",
    "(Outcome_for_treated  - Outcome_for_treated_if_not_treated) + (Outcome_for_treated_if_not_treated - Outcome_for_untreated) = \n",
    "Impact_of_treatment_on_treated + Selection_bias\n",
    "\n",
    "In AB-tests `Selection_bias = 0 → Exp_effect = Impact of treatment`\n",
    "But sometimes we can’t run ab-tests. We can use Observational Causal Studies\n",
    "\n",
    "Main questions:\n",
    "\n",
    "- how to construct control and treatment groups for comparison\n",
    "- how to model the impact on treatment group\n",
    "\n",
    "<u>The statistics in Online controlled Experiments</u>\n",
    "\n",
    "With normal distribution of (M2 - M1) we can use T-test. M - population mean.\n",
    "T = delta_M / sqrt(var(delta_M)) = delta_M / sqrt(var(M1) + var(M2))\n",
    "var(M) = var(population) / N\n",
    "\n",
    "`p_value = P(delta_observed | Ho=True)`\n",
    "Using Bayes: P(Ho=True | delta_observed) = p_value * P(Ho=True) / P(delta_observed)\n",
    "\n",
    "Main assumption: T-statistic has normal distribution\n",
    "M → Normal_dist (CLT)\n",
    "Minimum number of samples ⇒ depend of **skewness** coef. of sample sitribution\n",
    "`N_min ~ 355 * s**2; s = (M(Y - M(Y)))**3 / (Var(Y))**(3/2)`\n",
    "\n",
    "**Power** is the probability of detecting a difference between the variants , that is, rejecting the null, when there really is a difference. `Power = 1 - Type_2_error`\n",
    "\n",
    "With power=80%, alpha=5% and mean normal distribution, we can calc N samples:\n",
    "N ~ 16 * var(Y) / mde**2; mde = min_detective(M2 - M1)\n",
    "\n",
    "<u>Multiple Testing</u>\n",
    "\n",
    "When you have too much metrics (K metrics = K_per_exp * N_experiments)\n",
    "chance of random  “success” increased like `alpha_rand = K * alpha`\n",
    "\n",
    "Bonferroni adjustment: p_val ⇒ p_val / K. That’s too conservative.\n",
    "\n",
    "Common pipeline:\n",
    "- first-order metrics (expect to be impacted of experiment)\n",
    "- second-order metrics (potentially to be impacted - example, cannibalization)\n",
    "- third-order metrics (unlikely to be impacted)\n",
    "\n",
    "Use different p_value in groups: p_val_1 = 0.05; p_val_2 = 0.01; p_val_3 = 0.001\n",
    "**The stronger you believe that Ho is True - lower significance you should use**\n",
    "\n",
    "<u>Long and short term effects</u>\n",
    "\n",
    "Why long and short is differ:\n",
    "\n",
    "- user learned effects (positive or negative)\n",
    "- network effect or effect of resourses constraints (ex. num of cars, applicants etc)\n",
    "- delays between experience and target actions\n",
    "- sesonality, competitive\n",
    "- retention effects vs clickbaits and so on\n",
    "\n",
    "Methods to estimate long term effects:\n",
    "\n",
    "- **cohort analysis** (if cohort is representative to all traffic - it would be good proxy)\n",
    "You can use additional methods to improve the generalizability, such as a weighting adjustment based on stratification\n",
    "- **holdback experiments** (10% of users which use only Control version during several months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Теория"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://habr.com/ru/users/nnazarov/ - полезный цикл статей\n",
    "\n",
    "---\n",
    "Как описывали в Causal Inference, при рандомизированном разбиении выборки ничего не влияет на T.  \n",
    "В результате ATE = ATT; Влияние конфаундеров исчезает.  \n",
    "При этом остаются ряд других проблем связанных с оценкой эффекта через статистические тесты:  \n",
    "\n",
    "1. Проблема точности оценки ATE и связанная с ней длительность теста. См подробнее раздел по MDE \n",
    "2. Проблема применимости стат-теста к конкретной метрике (см подробнее раздел про Валидацию, сбалансированность)\n",
    "3. Проблемы множественных сравнений и работы с Ratio-метриками (линеаризация)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Variance reduction. CUPAC, CUPED, Stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://medium.com/glovo-engineering/variance-reduction-in-experiments-using-covariate-adjustment-techniques-717b1e450185  \n",
    "https://github.com/Glovo/covariate-adjustment-blogpost/tree/main  \n",
    "https://habr.com/ru/companies/X5Tech/articles/780270/\n",
    "\n",
    "---\n",
    "Из раздела \"Линейная регрессия\" (Causal inference) - в системе Y ~ T + X учет ковариат X, которые НЕ влияют на T  \n",
    "позволяет снижать дисперсию метрики Y -> увеличивать точность оценки ATE (по сути коэф. перед T = treatment).   \n",
    "Но это можно рассмотреть и так: Y - X = Y_adj ~ T; Y_adj = скорректированная по дисперсии метрика к Y.  \n",
    "Основные условия:\n",
    "1. avg(Y) = avg(Y_adj)\n",
    "2. std(Y_adj) < std(Y)\n",
    "3. Y ~ Y_adj (сонаправленность метрик)\n",
    "  \n",
    "Пусть у нас есть ковариата X, для которой cov(X, Y) > 0 при этом cov(X, T) = 0  \n",
    "Тогда согласно п.3: Y_predict = Yp = a0 + tetta * X , по методу наименьших квадратов tetta = cov(X,Yp) / var(X)  \n",
    "Рассмотрим Y_adj = Y - Yp + avg(Yp):\n",
    "видно что avg(Y_adj) = avg(Y)  \n",
    "т.к X объясняет часть вариации Y -> std(Y_adj) < std(Y)  \n",
    "Y_adj ~ Y по методу построения Yp.  (К слову, рандомная X не подходит, так как будет плохо предсказывать Y в регрессии)\n",
    "  \n",
    "С точки зрения длительности AB: N ~ var(X)/mde^2(X) -> уменьшая дисперсию метрики, можно пропорционально снижать N.\n",
    "  \n",
    "<u>CUPED = Controlled-experiment Using Pre-Experiment Data</u>  \n",
    "Если в качестве X использовать Y_prev = значения метрики на пред-экспериментальном периоде (до влияния T), то  \n",
    "Y_adj = Y_cuped = Y - Yp + avg(Yp) = Y - tetta * (Y_prev - avg(Y_prev))  \n",
    "Пре-экспериментальный период никак не может повлиять на T -> условие выполняется.  \n",
    "Если брать не очень большой период (например, последние 2 недели) -> достигается адекватная cov(Y, Y_prev).  \n",
    "  \n",
    "<u>Мультиковариатная регрессия</u>  \n",
    "CUPED - частный случай, когда мы используем Y_prev как ковариату-предиктор для Y в уравнении Y ~ T + Y_prev  \n",
    "Если мы знаем другие предикторы, уточняющие поведение Y, которые НЕ влияют на T, то Y ~ T + X1 + X2 + ...  \n",
    "Учет таких предикторов повышает точность оценки ATE (см ниже пример в коде)\n",
    "  \n",
    "<u>CUPAC = Control Using Predictors as Covariates</u>  \n",
    "CUPAC - расширение над уравнением регрессии с использованием ML, когда для снижения вариации целевой метрики Y  \n",
    "используются модели вроде случ. лесов итд.  \n",
    "Идея: имеем ковариаты X1, X2, ... Y_prev -> обучаем модель ML(X1, X2 .., Y_prev) -> Y_forecast.  \n",
    "Используем Y_forecast как ключевую ковариату в уравнении Y ~ T + Y_forecast.  \n",
    "PS. CUPED - частный случай CUPAC с одной ковариатой Y_prev   \n",
    "PSS. Мультирегрессия - частный случай CUPAC где ML-модель - линейная регрессия.  \n",
    "<u>Во всех</u> случаях Y_adj = Y - tetta * (Y_forecast - avg(Y_forecast))  \n",
    "std(Y_adj) < std(Y); avg(Y_adj) = avg(Y)  \n",
    "    \n",
    "<u>Подбор ковариат и пред-тестового периода</u>      \n",
    "Главное условие: ковариаты Y_prev, X1, X2, ... - никак не влияют на распределение T и обратно: cov(Y_forecast, T) = 0  \n",
    "Поэтому их берут на пред-тестовом периоде, чтобы Y_forecast = ML.fit(X1, ...) точно не зависело от последующего T.  \n",
    "   \n",
    "При выборе пред-тестового периода можно использовать знания о сезонности (искать аналогичный сезон в прошлом).  \n",
    "Размер пред-тестового периода может варьироваться (от exp_duration и больше)\n",
    "Подбор пред-тестового периода можно совершать, каждый раз оценивая насколько Y_adj(Y_forecast) снижает дисперсию относительно Y. \n",
    "  \n",
    "CUPAC/CUPED также можно использовать для бинарных метрик (вроде конверсии) - он будет улучшать чувствительность оценок.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# генерация данных\n",
    "n = 5000\n",
    "data = pd.DataFrame({\n",
    "    'T': np.random.binomial(1, 0.5, size=n),\n",
    "    'Y': np.random.normal(size=n),\n",
    "    'Y_prev': np.random.normal(size=n),\n",
    "    'Cov2': np.random.normal(size=n),\n",
    "})\n",
    "effect = 2\n",
    "\n",
    "# пре-тестовый период (нет зависимости T так как нет еще теста)\n",
    "data_prev = data[:2500] \n",
    "# data_prev['Y'] += 3 * data_prev['Y_prev'] + 4 * data_prev['Cov2']\n",
    "data_prev['Y'] += 3 * data_prev['Y_prev'] + 4 * data_prev['Cov2']**2\n",
    "\n",
    "\n",
    "# тестовый период\n",
    "data_now = data[2500:]\n",
    "# data_now['Y'] += effect * data_now['T'] + 3 * data_now['Y_prev'] + 4 * data_now['Cov2'] \n",
    "data_now['Y'] += effect * data_now['T'] + 3 * data_now['Y_prev'] + 4 * data_now['Cov2']**2 \n",
    "\n",
    "\n",
    "# реализация CUPED\n",
    "# в AB тесте оценку tetta можно проводить как по now, так и по prev данным.\n",
    "# если размеры AB групп достаточно велики, лучше оценивать tetta на объединённых данных контрольной и экспериментальной групп. \n",
    "# Если размеры групп малы, то оценка tetta на исторических данных может дать лучшее качество.\n",
    "def get_cuped_adj(Y, Y_prev):\n",
    "    # Y = целевая метрика; Y_prev эта же метрика на клиентах на пред-тестовом периоде\n",
    "    tetta = np.cov(Y, Y_prev)[0][1] / np.var(Y_prev)\n",
    "    return Y - (Y_prev - np.mean(Y_prev)) * tetta\n",
    "\n",
    "# оценка ATE через регрессию\n",
    "def get_est(formula, df, text):\n",
    "    model = smf.ols(formula, data=df).fit()\n",
    "    conf = np.round(model.conf_int().loc['T'], 3); std = round(model.bse.loc['T'], 3)\n",
    "    print(f'{text}: ate = {conf[0]} - {conf[1]}; std_ate = {std}')\n",
    "    \n",
    "# Пример использования CUPAC: получаем y_forecast = ML(X1, X2 ...) через древесный регрессом; корректируем Y\n",
    "def get_cupac_adj(X_past, Y_past, X, Y):\n",
    "    # X_past, Y_past - фичи и целевая метрика на предэкспериментальном периоде\n",
    "    # X, Y - фичи и метрика в эксперименте - для предикта Y_forecast и поправки\n",
    "    gbm = HistGradientBoostingRegressor().fit(X_past, Y_past)\n",
    "    Y_forecast = gbm.predict(X)\n",
    "    return get_cuped_adj(Y, Y_forecast)\n",
    "\n",
    "\n",
    "Y_cuped = get_cuped_adj(data_now.Y, data_now.Y_prev)\n",
    "Y_cupac = get_cupac_adj(\n",
    "                      data_prev[['Y_prev', 'Cov2']].values, # целевая метрика пред-тестового периода\n",
    "                      data_prev.Y.values, # целевая метрика пред-тестового периода\n",
    "                      data_now[['Y_prev', 'Cov2']].values,\n",
    "                      data_now.Y.values\n",
    "                     )\n",
    "\n",
    "data_now['Y_cuped'] = Y_cuped\n",
    "data_now['Y_cupac'] = Y_cupac\n",
    "\n",
    "print(f'реальный ATE = {effect}')\n",
    "get_est('Y ~ T', data_now, 'без редукции VAR')\n",
    "get_est('Y_cuped ~ T', data_now, 'CUPED - формула')\n",
    "get_est('Y ~ T + Y_prev', data_now, 'CUPED, как частный случ. мультиковар. регрессии')\n",
    "get_est('Y ~ T + Y_prev + Cov2', data_now, 'Мультиковар. регрессия')\n",
    "get_est('Y_cupac ~ T', data_now, 'CUPAC обученный на prev-периоде')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<u>STRATIFICATION</u>  \n",
    "https://habr.com/ru/companies/yandex/articles/497804/  \n",
    "https://habr.com/ru/companies/X5Tech/articles/596279/  \n",
    "https://habr.com/ru/companies/X5Tech/articles/826488/  \n",
    "\n",
    "---\n",
    "<u>Ключевая идея</u>    \n",
    "заменяем среднее для метрики X на средневзвешенное по стратам.\n",
    "Страта - группа с одинаковым значением S = комбинированной ковариаты страты.  \n",
    "  \n",
    "Например, Y - сумма покупок компаний; X - сегмент бизнеса, возраст компании; S = {SMB_new, SMB_old, Large_new, ....}.  \n",
    "При этом SMB_new, SMB_old ... это конкретные страты, по которым будем взвешивать среднее.  \n",
    "Для составления вектора S можно использовать как простую конкантенацию так и kNN методы.  \n",
    "  \n",
    "Веса каждом страты W_s = len(X in S) / len(X) = вероятности, оцениваются на пред-экспериментальном периоде.  \n",
    "Среднее тогда avg_strat(X) = sum(W_s * avg(X in S)); std_strat_X < std_X.  \n",
    "Причина снижения дисперсии - фильтрация меж-стратовой дисперсии (см \"Статистика\") - остается только внутри-стратовая.  \n",
    "Снижение тем выше - <u>чем сильнее разница средних между стратами</u> (то есть выше межгрупповая дисперсия)\n",
    "  \n",
    "Важное условие: cov(S, T) = 0, метрика S не влияет на экспериментальную разбивку, существует до и после начала теста.  \n",
    "Сам тест также не влияет на метрику S.\n",
    "  \n",
    "Стратификация классическая и пост-стратификация:\n",
    "1. Классическая - когда мы семплируем A/B группы следя за равномерным наполнением страт и затем применяем avg_strat_ttest  \n",
    "2. Пост - когда мы семплируем без контроля равномерности страт (как обычно), но далее также применяем avg_strat_ttest  \n",
    "Различия в оценках std методами 1 и 2 стремятся к нулю при большом кол-ве данных (>1e3) -> обычно можно идти по пути 2.\n",
    "  \n",
    "Выбор признаков для S можно осуществлять на исторических данных исходя из условия:  \n",
    "максимальная меж-групповая дисперсия среднего целевой метрики посчитанной по разным стратам.  \n",
    "\n",
    "---\n",
    "СUPAC vs Stratification.  \n",
    "В большинстве случаев, если использовать S в CUPAC для предикта Y_forecast, то снижение  \n",
    "дисперсии тотал метрики за счет обнуления межгрупповой дисперсии уже будет учтено в алгоритме.  \n",
    "Поэтому использование стратификации поверх CUPAC не даст значительного улучшения.  \n",
    "  \n",
    "Исключение - если после старта эксперимента проихошло <u>не зависящее от эксперимента</u>  влияние на метрику Y  \n",
    "конкретно в каких-то стратах (например, сезонный рост покупок в сегменте LARGE которого не было на пред-периоде).  \n",
    "В этом случае, Y_forecast не учтет выросшую в тесте межгрупповую дисперсию, а методы стратификации поверх CUPAC  \n",
    "смогут ее контролировать. Поэтому в общем случае полезно использовать оба метода.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# сгенерируем тестовые данные; Y будет зависеть от значения страт\n",
    "# чем больше разброс id страт - тем больше разброс Y_strat - лучше работает стратификация\n",
    "size = 5000\n",
    "effect = 0.01\n",
    "std = 3\n",
    "strat_seq = [1, 2, 5]\n",
    "\n",
    "# распределение страт на пред-экспериментальном периоде\n",
    "df_prev = pd.DataFrame({'S' : np.random.choice(strat_seq, size=size)})\n",
    "weights = df_prev.S.value_counts(normalize=True) # series\n",
    "\n",
    "df_con = pd.DataFrame({'S' : np.random.choice(strat_seq, size=size)})\n",
    "df_con['Y'] = df_con['S'].apply(lambda x: np.random.normal(x**2, std))\n",
    "\n",
    "df_test = pd.DataFrame({'S' : np.random.choice(strat_seq, size=size)})\n",
    "df_test['Y'] = df_test['S'].apply(lambda x: np.random.normal(x**2 + effect, std))\n",
    "\n",
    "conf1 = ht.ttest_stratification_calc(df_con, df_test, weights)[0] # пост стратификация\n",
    "conf2 = ht.ttest_calc(df_con.Y, df_test.Y)[0] # классический тест\n",
    "print(f\"\"\"conf_width: classic test = {round(conf2[1] - conf2[0], 4)}; stratification = {round(conf1[1] - conf1[0], 4)}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Длительность теста и MDE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "MDE = Minimum Detectable Effect = минимальное изменение которое будет детектируемо через стат-тест с  \n",
    "выбранными уровнями ошибки первого и второго рода.  \n",
    "  \n",
    "В случае с T-тестом (см страничку \"Статистика\") оцениваем delta = avg(control) - avg(experiment).  \n",
    "Дисперсия средневыборочного std_X_mean = std(X)/sqrt(N), N - длина выборки.  \n",
    "Поэтому мин. детектируемая delta средних: mde = T(alpha, power) * std(X) / sqrt(N).  \n",
    "  \n",
    "Отсюда следует, что N (кол-во клиентов aka длительность теста) ~ var(X) / mde^2.  \n",
    "Чем меньше var(X) = шум метрики - тем меньше данных надо для фиксированной точности.  \n",
    "Кроме того с ростом ожидаемого mde квадратично падает N\n",
    "  \n",
    "1) Учитывая в дизайне АБ теста рост mde - можно квадратично ускорять его.  \n",
    "Пример: замеряем как изменится рост выручки X от роста цены на 10%.  \n",
    "Если запустить тест в формате (уменьшили цену на 10%) VS (увеличили цену на 10%), то  \n",
    "ожидаемая дельта эффекта удвоится -> данных надо будет гораздо меньше.  \n",
    "  \n",
    "2) Другой вариант - сокращать var(X) - см подробнее в разделе \"Variance reduction\"  \n",
    "\n",
    "Приложение:  \n",
    "При оценке mde эксперимента на контрольной выборке, полагаем что std_experiment = std_control.  \n",
    "В будущем, на накопленных данных control/experiment можно посчитать mde_real(control, experiment).  \n",
    "Тогда в формуле std будет учитываться как sqrt(std_control^2 + std_experiment^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "control, test = np.random.normal(1, 1, 1000), np.random.normal(1.2, 1, 1000)\n",
    "ht.ttest_calc(control, test) # confint; pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# пример оценки MDE\n",
    "control = np.random.normal(1, 1, 1000)\n",
    "ht.get_mde_detail(control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Сбалансированность и репрезентативность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Репрезентативность - обобщаемость используемой выборки на всю генеральную совокупность.   \n",
    "При нестационарном поведении генеральной совокупности во времени необходимо случайно  \n",
    "семплировать выборку для теста также по времени.   \n",
    "2. Сбалансированность - условия по возможности попадания семплов в выборку в тесте/контроле должны быть одинаковые  \n",
    "Перекос в размере выборки относительно ожидаемой показывает на ошибкув рандомизации.  \n",
    "  \n",
    "---\n",
    "Тест на сбалансированность через хи-квадрат:  \n",
    "  \n",
    "Критерий соответствия эмпирических частот ожидаемым.  \n",
    "При сравнении номинативных признаков образуется таблица сопряженности с совместными частотами.  \n",
    "Она же образуется, если сравниваем теоретическое и реальное распределения вероятностей.  \n",
    "Частный случай таблицы - вектор эмпирических частот признака (например частоты орла/решки).  \n",
    "\n",
    "H0-гипотеза: наблюдаемые частоты совпадают с ожидаемыми (теоретическими).  \n",
    "В этом случае chi^2 = sum((Obs - Exp)^2 / Exp) -- расстояние Пирсона.  \n",
    "Для таблицы размерностью ij критерий будет удовлетворять df = (i-1)(j-1) степень свободы.  \n",
    "Так как мы знаем тотал значения таблицы и значит одна степень свободы всегда фиксирована.  \n",
    "\n",
    "PS. Величина Obs распределена биномиально (вероятность попасть в ячейку j Obs раз).  \n",
    "При малых вероятностях получаем Пуассона, где std^2=mean=Exp при нулевой гипотезе. Тогда t-score  \n",
    "(Obs - Mean) / Std ~ (Obs - Exp)/sqrt(Exp) ~ N(0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Оценка сбалансированности выборок в АБ тесте\n",
    "f_real = [100, 110, 105]\n",
    "print('Три ветки, ожидаемое распределение равномерно: ', ht.check_branch_balance(f_real))\n",
    "f_real = [85, 20]; f_exp = [80, 20]      \n",
    "print('Две ветки, катим тест 80/20: ', ht.check_branch_balance(f_real, f_exp))\n",
    "f_real = [100, 20]; f_exp = [80, 20]      \n",
    "print('Две ветки, катим тест 80/20: ', ht.check_branch_balance(f_real, f_exp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Множественные сравнения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://habr.com/ru/articles/772940/\n",
    "  \n",
    "При проведении A/B/C... = N тестов могут возникнуть такие задачи:\n",
    "1. Определить ветку-победителя. Потребуется сделать K = N * (N-1) / 2 стат-тестов, проверяя каждую пару веток.\n",
    "2. Найти хотя бы одну ветку, лучшую чем контроль. Здесь требуется совершить N сравнений с контролем.  \n",
    "3. Остановить тест если хотя бы одна из K значимых метрик прокрасится отрицательно (даже в простом A/B тесте)\n",
    "\n",
    "Проблема в контроле ошибки первого рода: если не использовать поправки на множественное сравнение,  \n",
    "то например вероятность найти хотя бы один прокрас FWER = 1 - (1 - alpha)^N ~ alpha * N >> alpha \n",
    "\n",
    "В зависимости от консервативности контроля выделяют два типа множественных корректировок:\n",
    "\n",
    "1. Контроль FWER = family-wise error rate = вероятность совершить хотя бы одну ошибку при проверке X тестов.  \n",
    "Хотя бы одну ошибку сделали = сделали неправильное решение на базе группы.  \n",
    "Считаем любую ошибку критичной и ожидаем ее появление в небольшое кол-ве случаев.  \n",
    "Используют поправку Бонферрони (alpha_adj = alpha / N); поправку Холма (более мощная), Тьюкки итд.  \n",
    "По мощности оптимально использовать метод Холма\n",
    "\n",
    "2. Контроль FDR = false discovery rate = доля всех ложных прокрасов среди тестов, которые <u>прокрасились</u>  \n",
    "Здесь допускаем чтобы из K прокрашенных тестов у нас было alpha% прокрашенных по ошибке.  \n",
    "Подходит, когда фильтруем интересные инсайты и допускаем наличие среди них доли ложно-прокрашенных.  \n",
    "Мощность в среднем, очевидно, выше чем при контроле FWER\n",
    "Здесь по мощности оптимально использовать метод Бенджамини-Хохберга  \n",
    "\n",
    "Чем эффективнее идет контроль FWER (шанс хотя бы одного ложного прокраса), тем хуже чувствительность, например  \n",
    "метрика FWER-II (шанс хотя бы одного случая, когда не заметили реальный прокрас).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fwer_list, tn_list = [], []\n",
    "fwer_list2, tn_list2 = [], []\n",
    "fwer_list3, tn_list3 = [], []\n",
    "fwer_list4, tn_list4 = [], []\n",
    "\n",
    "def get_effect(real_effect, p_val_list):\n",
    "    fp = [] # ошибка первого рода\n",
    "    tn = [] # ошибка второго рода\n",
    "    for idx, p_val in enumerate(p_val_list):\n",
    "        if real_effect[idx] == 0 and p_val < 0.05: # FP\n",
    "            fp.append(1); tn.append(0)\n",
    "        elif real_effect[idx] == 0 and p_val >= 0.05: # FN\n",
    "            fp.append(0); tn.append(0)\n",
    "        elif real_effect[idx] == 1 and p_val < 0.05: # TP\n",
    "            fp.append(0); tn.append(0)\n",
    "        elif real_effect[idx] == 1 and p_val >= 0.05: # TN\n",
    "            fp.append(0); tn.append(1)\n",
    "            \n",
    "    fwer = max(fp) # хотя бы один ложный прокрас в группе\n",
    "    fwer_II = max(tn) # не нашли хотя бы один реальный прокрас в группе\n",
    "    return fwer, fwer_II\n",
    "\n",
    "for _ in range(1000):\n",
    "    \n",
    "    # генерируем одинаковые ветки\n",
    "    test_list = []\n",
    "    for _ in range(3): # кол-во веток\n",
    "        test_list.append(np.random.normal(1, 1, 200)) # mu, std, size\n",
    "        \n",
    "    # добавляем ветку с реальным эффектом\n",
    "    eff_delta = 0.3\n",
    "    test_list.append(np.random.normal(1 + eff_delta, 1, 200))\n",
    "    idx_last = len(test_list) - 1\n",
    "    \n",
    "\n",
    "    # попарное вычисление тестов\n",
    "    p_val_list = []\n",
    "    real_effect = []\n",
    "    for idx, test in enumerate(test_list):\n",
    "        for idx2, test2 in enumerate(test_list):\n",
    "            if idx > idx2:\n",
    "                p_val_list.append(stats.ttest_ind(test, test2)[1])\n",
    "                \n",
    "                # помечаем если имеется реальное различие в тестах\n",
    "                if idx == idx_last or idx2 == idx_last:\n",
    "                    real_effect.append(1)\n",
    "                else:\n",
    "                    real_effect.append(0)\n",
    "                \n",
    "    # корректировки p_val для множественного сравнения\n",
    "    p_val_bonf = multipletests(p_val_list, alpha = 0.05, method='bonferroni')[1] # holm\n",
    "    p_val_holm = multipletests(p_val_list, alpha = 0.05, method='holm')[1] # holm\n",
    "    p_val_bh = multipletests(p_val_list, alpha = 0.05, method='fdr_bh')[1] # Benjamini/Hochberg \n",
    "\n",
    "    # принятие решения по группе - расчет коллективного ложного прокраса и ошибки 2-го рода\n",
    "    fwer, fwer_II = get_effect(real_effect, p_val_list)\n",
    "    fwer_list.append(fwer); tn_list.append(fwer_II)\n",
    "    \n",
    "    fwer, fwer_II = get_effect(real_effect, p_val_bonf)\n",
    "    fwer_list2.append(fwer); tn_list2.append(fwer_II)\n",
    "    \n",
    "    fwer, fwer_II = get_effect(real_effect, p_val_holm)\n",
    "    fwer_list3.append(fwer); tn_list3.append(fwer_II)\n",
    "    \n",
    "    fwer, fwer_II = get_effect(real_effect, p_val_bh)\n",
    "    fwer_list4.append(fwer); tn_list4.append(fwer_II)\n",
    "\n",
    "# статистики для разных подходов\n",
    "print(f'No correction. FWER = {np.mean(fwer_list)}; FWER-II = {round(np.mean(tn_list), 5)}')\n",
    "print(f'Bonferroni-FWER correction. FWER = {np.mean(fwer_list2)}; FWER-II = {round(np.mean(tn_list2), 5)}')\n",
    "print(f'Holm-FWER correction. FWER = {np.mean(fwer_list3)}; FWER-II = {round(np.mean(tn_list3), 5)}')\n",
    "print(f'BH-FDR correction. FWER = {np.mean(fwer_list4)}; FWER-II = {round(np.mean(tn_list4), 5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Валидация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://habr.com/ru/companies/hh/articles/321386/  \n",
    "https://habr.com/ru/companies/X5Tech/articles/706388/\n",
    "\n",
    "---\n",
    "Когда мы работаем с метрикой X и планируем оценивать ее изменение в AB тесте, используя статистический тест,  \n",
    "нужно перед этим убедиться, что пройдена валидация метрики для этого теста.  \n",
    "  \n",
    "Валидация:\n",
    "убеждаемся, что при выбранной для теста ошибке первого рода - на группе АА-тестов доля ложных  \n",
    "прокрасов (FPR) соответствует этой ошибке.  \n",
    "PS. В общем случае через АА тест можно проверить любой тип теста (Манна-Уитни, bootstrap итд)    \n",
    "Подробнее рассмотрим T-test на средних, как наиболее часто используемый.  \n",
    "  \n",
    "Ситуация, когда метрика не проходит валидацию:\n",
    "1. Выбросы в метрике -> не выполняется ЦПТ -> средневыборочное не распределено нормально (см \"Статистика\")\n",
    "2. Семплы зависимы -> не выполняются классические операции над вероятностями -> нарушение нормальности\n",
    "3. Слишком мало данных\n",
    "  \n",
    "При валидации T-теста, мы разбиваем выборку на случайные пары АА-фрагментов, вычисляем p_val и оцениваем  \n",
    "долю ложных прокрасов с доверительным интервалом.  \n",
    "Дополнительно можно посмотреть на нормальность средневыборочного (необходимое условие валидации, но не достаточное)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# пример адекватной для T-теста метрики\n",
    "X = np.random.normal(1, 1, 1000) \n",
    "ans, p_val_list, avg_list = ht.validation_ttest(X)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# пример метрики с дополнительными \"выбросами\"\n",
    "X = np.append(np.random.normal(1, 1, 1000), np.random.normal(1000, 1, 9)) \n",
    "ans, p_val_list, avg_list = ht.validation_ttest(X)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Последовательный анализ, бакетный и децильный анализы TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# todo\n",
    "# https://www.youtube.com/watch?v=p_5YzShN4sg\n",
    "# децильное распределение val_list1, val_list2 на основании бутстрапа\n",
    "# N-й дециль -> доверительный интервал , контрольное значение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Ratio-метрики. Дельта метод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://habr.com/ru/companies/X5Tech/articles/740476/\n",
    "https://habr.com/ru/company/avito/blog/454164/\n",
    "\n",
    "---\n",
    "\n",
    "Метрика типа R = X / Y (например средняя длительность сессии на сайте по всем клиентам).  \n",
    "R = (x1 + x2 + ...) / (y1 + y2 + ...)  \n",
    "В общем случае x1, x2, ... зависимые, так как один клиент может создавать несколько сессий и пр.  \n",
    "Поэтому, нельзя работать с параметрическими тестами вроде t-test.  \n",
    "(зависимость -> не работают теоремы сложения/умножения вероятностей -> не работают все распределения).  \n",
    "  \n",
    "1. Чтобы начали работать классические тесты - необходимо превратить Ratio-метрику в поюзерную  \n",
    "R = X / Y = alpha * X + betta * Y + gamma  \n",
    "Поюзерная метрика -> пренебрегая зависимостью между юзерами -> подходит под i.i.e\n",
    "Один из вариантов такого разложения - ряд Тейлора в точке avg(X)/avg(Y). \n",
    "Можно разложить до первого члена (линеаризация) или взять больше точности и след члены ряда.\n",
    "  \n",
    "2. Можно использовать bootstrap для семплирования Ratio  \n",
    "Для него нет проблем с тем что распределение не нормальное, но это вычислительно дорого  \n",
    "  \n",
    "3. Есть дельта-метод оценки дисперсии метрики X/Y (см статью)  \n",
    "Он считается быстро и удобен в оценке критериев, но не дает поюзерную метрику с которой потом удобно работать,  \n",
    "например увеличивая чувствительность и пр.\n",
    "\n",
    "---\n",
    "<u>Дельта-метод</u>  \n",
    "https://www.linkedin.com/pulse/дельта-метод-от-а-до-я-bogdan-pilyavets/?originalSubdomain=ru  \n",
    "Ключевая идея: если функция g(X) асимптотически нормально распределена по X, то  \n",
    "ее можно представить в виде g -> (n inf) -> g(X0) + (X - X0) * dg/dx ~ N(0, std)  \n",
    "Аналогичное разложение работает в многомерном сценарии g(X,Y,Z...) в ряд Тейлора.  \n",
    "std зависит от производных функции g в опорной точке 0.\n",
    "Доказательство = разложение в ряд Тейлора + применение ЦПТ.  \n",
    "  \n",
    "Частный случай: g = g(X,Y) = X/Y -> avg(X/Y) + dg/dx * (X-avg_X) + dg/dy * (Y-avg_Y).  \n",
    "Отсюда линеарзиация: разложение ratio-метрики в поюзерную, std(X/Y) ~ std(dg/dx * ...) - считается.    \n",
    "P.S для метрики X/Y также критично avg_Y > 0; std(X), std(Y) конечны (эффект выбросов не значителен)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# семплируем отдельных \"юзеров\" по индексам\n",
    "def ratio_bootstrap_calc(num_list1, denum_list1, num_list2, denum_list2, iter_=10**4, alpha=0.05):\n",
    "    boot_list = []\n",
    "    for _ in range(iter_):   \n",
    "        idx = np.random.choice(np.arange(len(num_list1)), len(num_list1), replace=True)\n",
    "        idx2 = np.random.choice(np.arange(len(num_list2)), len(num_list2), replace=True)\n",
    "        num_list1_, denum_list1_ = num_list1[idx], denum_list1[idx]\n",
    "        num_list2_, denum_list2_ = num_list2[idx2], denum_list2[idx2]\n",
    "        delta = sum(num_list2_) / sum(denum_list2_) - sum(num_list1_) / sum(denum_list1_)\n",
    "        boot_list.append(delta)\n",
    "    # confint \n",
    "    return np.quantile(boot_list, [alpha/2, 1 - alpha/2])\n",
    "\n",
    "# превращаем метрику в поюзерную раскладывая в ряд тейлора до первого члена (дельта метод)\n",
    "def ratio_taylor(metric_num, metric_denum):\n",
    "    \"\"\"\n",
    "    X/Y ~ mx/my + 1/my * (X - mx) - mx/my**2 * (Y - my) = mx/my + 1/my(X - Y*mx/my)\n",
    "    https://habr.com/ru/company/avito/blog/454164/\n",
    "    \"\"\"\n",
    "    mx, my = np.mean(metric_num), np.mean(metric_denum)\n",
    "    return mx / my + (1 / my) * (metric_num - metric_denum * (mx / my))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_list1 = np.random.normal(1, 1, 1000)\n",
    "denum_list1 = np.random.normal(2, 1, 1000)\n",
    "num_list2 = np.random.normal(1, 1, 1000)\n",
    "denum_list2 = np.random.normal(3, 1, 1000)\n",
    "ratio_bootstrap_calc(num_list1, denum_list1, num_list2, denum_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "linear1 = ratio_taylor(num_list1, denum_list1)\n",
    "linear2 = ratio_taylor(num_list2, denum_list2)\n",
    "print('линеаризация + поюзерный ttest дают корректный результат как bootstrap')\n",
    "ht.ttest_calc(linear1, linear2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
